{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfridland/NLP/blob/HW8/NLP_DF_HW8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofS3jluhVuLn"
      },
      "source": [
        "# Урок 8. Рекуррентные нейронные сети RNN, LSTM, GRU\n",
        "\n",
        "## Домашнее задание."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRhgJYQWVuLo"
      },
      "source": [
        "Данные берем `'отзывы за лето'`\n",
        "\n",
        "На вебинаре мы говорили, что долгое время CNN и RNN архитектуры были конурируещими выяснить какая архитектура больше подходит для нашей задачи\n",
        "\n",
        "1. построить свёрточные архитектуры\n",
        "2. построить различные архитектуры с RNN\n",
        "3. построить совместные архитектуры CNN -> RNN и/или (RNN -> CNN)\n",
        "4. сделать выводы что получилось лучше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFEER9cWYKXi",
        "outputId": "12743f65-107c-4796-f201-35403aab5e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /Users/evamelissatasdemir/miniforge3/lib/python3.10/site-packages (2018.7.23)\n",
            "Requirement already satisfied: pymorphy2 in /Users/evamelissatasdemir/miniforge3/lib/python3.10/site-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /Users/evamelissatasdemir/miniforge3/lib/python3.10/site-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /Users/evamelissatasdemir/miniforge3/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/evamelissatasdemir/miniforge3/lib/python3.10/site-packages (from pymorphy2) (2.4.417127.4579844)\n"
          ]
        }
      ],
      "source": [
        "!pip install stop_words\n",
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSa1DsNaluOK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "THZpMkXClbDG",
        "outputId": "97ace70b-bafa-48c2-9632-9fbb90f1a6e7"
      },
      "source": [
        "# %cd /content/drive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuXvnskTZPbd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n",
        "df_train = pd.read_csv(\"./lection8/data/train.csv\")\n",
        "df_test = pd.read_csv(\"./lection8/data/test.csv\")\n",
        "df_val = pd.read_csv(\"./lection8/data/val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sHoL4likZ7ux",
        "outputId": "c44daf42-c96c-454e-ede6-03cf774806af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5IPZtB2aCmI"
      },
      "outputs": [],
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw] #долгая Каноническая форма слова (например, форма единственного числа, именительного падежа для существительных)\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMMrtH--aUzm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "#import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, Conv2D, GlobalMaxPool1D, concatenate, Flatten, add, MaxPool1D, RepeatVector\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Masking, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, TimeDistributed, AveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.utils.data_utils import pad_sequences\n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-mOllPbaduF"
      },
      "outputs": [],
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy2xqMn-cK1t"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train) #Текст в последовательности\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length) #Эта функция преобразует список (длиной num_samples) последовательностей (списков целых чисел) в двумерный массив Numpy \n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CShnSo8KcbjN"
      },
      "outputs": [],
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XUBIUd0ny5-"
      },
      "source": [
        "### RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pA6CzKdVuLs"
      },
      "outputs": [],
      "source": [
        "# tf.config.set_visible_devices([], 'GPU')\n",
        "# with tf.device('/cpu:0'):\n",
        "physical_devices = tf.config.list_physical_devices('GPU'); \n",
        "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbVA54XnnyQm",
        "outputId": "31efc789-e37b-4b28-e01d-877c16f30d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 502s 2s/step - loss: 0.6820 - accuracy: 0.5402 - val_loss: 0.5778 - val_accuracy: 0.6948\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 361s 1s/step - loss: 0.4620 - accuracy: 0.7848 - val_loss: 0.5214 - val_accuracy: 0.7385\n",
            "Epoch 3/10\n",
            "319/319 [==============================] - 364s 1s/step - loss: 0.1892 - accuracy: 0.9280 - val_loss: 0.6574 - val_accuracy: 0.7267\n"
          ]
        }
      ],
      "source": [
        "model_name = 'RNN'\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
        "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
        "              output_dim=30, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
        "model.add(SimpleRNN(32, recurrent_dropout=0.2, return_sequences=True)) #возвращать всю последовательность выходных данных для каждого элемента (по одному вектору на каждый шаг)\n",
        "model.add(SimpleRNN(32, recurrent_dropout=0.2))#отбрасывание линейных значений повторов 0.2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss') #Класс EarlyStopping Остановить обучение, когда отслеживаемая метрика перестанет улучшаться \n",
        "\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs/'+ model_name, \n",
        "    write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwM8pG39PIJr",
        "outputId": "2bc41fba-1ac2-47b7-e119-64af7fb4fa02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 5s 104ms/step - loss: 0.6659 - accuracy: 0.7226\n",
            "\n",
            "\n",
            "Test score: 0.6658899784088135\n",
            "Test accuracy: 0.722611665725708\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbjZM-FAq6oF"
      },
      "source": [
        "### CNN -> RNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-OfjmHoosEm"
      },
      "outputs": [],
      "source": [
        "model_name = 'CNN -> RNN'\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
        "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
        "              output_dim=64, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
        "model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
        "model.add(SimpleRNN(64, recurrent_dropout=0.2)) #отбрасывание линейных значений повторов 0.2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss') #Класс EarlyStopping Остановить обучение, когда отслеживаемая метрика перестанет улучшаться \n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs/'+ model_name, \n",
        "    write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYacBPbPrydf",
        "outputId": "18b0a096-35a6-4767-834e-2f3b2fb8ff88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 138s 428ms/step - loss: 0.5907 - accuracy: 0.6635 - val_loss: 0.5044 - val_accuracy: 0.7459\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 131s 409ms/step - loss: 0.3405 - accuracy: 0.8556 - val_loss: 0.5371 - val_accuracy: 0.7465\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Tygx31rMQo"
      },
      "source": [
        "### RNN -> CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2msS2UpwgcO"
      },
      "outputs": [],
      "source": [
        "model_name = 'RNN -> CNN'\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
        "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
        "              output_dim=64, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
        "model.add(SimpleRNN(64, recurrent_dropout=0.2, return_sequences=True)) #отбрасывание линейных значений повторов 0.2\n",
        "# model.add(RepeatVector(32))\n",
        "model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss') #Класс EarlyStopping Остановить обучение, когда отслеживаемая метрика перестанет улучшаться \n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs/'+ model_name, \n",
        "    write_graph=False, update_freq=100, profile_batch=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK6QAuP6zxm_",
        "outputId": "caceb641-3a7a-4cd6-c729-9753265a42fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 7s 132ms/step - loss: 0.6950 - accuracy: 0.5092 - val_loss: nan - val_accuracy: 0.4934\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 4s 114ms/step - loss: 0.6920 - accuracy: 0.5179 - val_loss: nan - val_accuracy: 0.5207\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOIWvCOlcggH"
      },
      "source": [
        "# LSTM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR_ROb13crym",
        "outputId": "a066d2e0-2c31-4ae2-ff57-adf102028386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/10\n",
            "319/319 [==============================] - 25s 77ms/step - loss: 0.5576 - accuracy: 0.7066 - val_loss: 0.4966 - val_accuracy: 0.7540\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 25s 78ms/step - loss: 0.3303 - accuracy: 0.8639 - val_loss: 0.5281 - val_accuracy: 0.7498\n",
            "CPU times: user 1min 32s, sys: 46.7 s, total: 2min 19s\n",
            "Wall time: 50.4 s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "# Run inference on CPU\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model_name = 'LSTM'\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(\n",
        "        Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
        "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
        "              output_dim=30, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "    model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
        "    model.add(LSTM(64, recurrent_dropout=0.2)) #отбрасывание линейных значений повторов 0.2\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stopping=EarlyStopping(monitor='val_loss') #Класс EarlyStopping Остановить обучение, когда отслеживаемая метрика перестанет улучшаться \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='logs/'+ model_name, \n",
        "        write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuI_FZFYc6_D",
        "outputId": "aa64e242-82e3-430b-a1a8-2260419382eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 6s 123ms/step - loss: 0.5650 - accuracy: 0.7384\n",
            "\n",
            "\n",
            "Test score: 0.5649610757827759\n",
            "Test accuracy: 0.7383943796157837\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSkPXrOqBrOu",
        "outputId": "18d3fc2e-f834-4520-d163-f76b4419eb87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['тектоника рельефсамый ужасный мир мучение',\n",
              "       'ходить запускать шар желание насна получиться хрен они',\n",
              "       'хотеть лето ради направить ноготь яркий лак', ...,\n",
              "       'rt killgayslut yournovocaine привеееть муд черта сэмми',\n",
              "       'настроение вроде нормальный плакать хотеться',\n",
              "       'зайти сон девчонкампока мыть посудунастя фоткаться httptcokinexudtuh'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.text.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT8cKwEeGA0V"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_for_prediction(txt):\n",
        "  txt = preprocess_text(txt)\n",
        "  txt = tokenizer.texts_to_sequences([txt])\n",
        "  matr_txt = pad_sequences(txt, maxlen=training_length)\n",
        "  mart_txt = matr_txt.reshape(1, -1)\n",
        "  return matr_txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgxWDGaVKjx2",
        "outputId": "db21f0dd-a177-40a7-8dfd-8ea0b7c98ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.12535053]], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(\n",
        "    [preprocess_text_for_prediction('тектоника рельефсамый ужасный мир мучение')],\n",
        "    batch_size=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5McsV1HKaw2",
        "outputId": "1440147f-f55d-4262-f4df-ae0492b2cce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.84056103]], dtype=float32)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(\n",
        "    [preprocess_text_for_prediction('Люблю смотреть на звезды')],\n",
        "    batch_size=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YQrd7Cyv07O",
        "outputId": "fd22ee9f-8a10-4ca6-93e1-9e55e418ba84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 135ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.808098]], dtype=float32)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(\n",
        "    [preprocess_text_for_prediction('Великолепно!')], \n",
        "    batch_size=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0V7R8osLKpG"
      },
      "source": [
        "### Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrYzxF3gdCET",
        "outputId": "637e2347-081d-4b39-d511-aece9cbaae23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 534 ms, sys: 85.4 ms, total: 619 ms\n",
            "Wall time: 513 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run inference on CPU\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model_name = 'Bidirectional LSTM'\n",
        "    inputs = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "    x =     Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True)(inputs)\n",
        "\n",
        "    xbi = Bidirectional(LSTM(15, return_sequences=True))(x) #Двунаправленный\n",
        "    x = add([x, xbi])\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTFmgM4jdElR",
        "outputId": "3055016f-c21d-4099-c8b0-cc462fd4d8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 11s 28ms/step - loss: 0.5508 - accuracy: 0.7086 - val_loss: 0.4873 - val_accuracy: 0.7590\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 9s 27ms/step - loss: 0.2985 - accuracy: 0.8779 - val_loss: 0.5381 - val_accuracy: 0.7460\n",
            "CPU times: user 51.9 s, sys: 17.5 s, total: 1min 9s\n",
            "Wall time: 19.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run inference on CPU\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='logs/'+ model_name, \n",
        "        write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "\n",
        "    history_1 = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijjl17HMdIEW",
        "outputId": "1c327d4e-2ce2-4955-af36-55aae7f01f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 8s 167ms/step - loss: 0.5663 - accuracy: 0.7343\n",
            "\n",
            "\n",
            "Test score: 0.5663064122200012\n",
            "Test accuracy: 0.7343384623527527\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRMrWwGdPww"
      },
      "source": [
        "#CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq4WzNJCdVDH",
        "outputId": "e0a50aca-3eb7-42fb-ffc6-e89ae4137822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 51 ms, sys: 63 ms, total: 114 ms\n",
            "Wall time: 138 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run training on GPU\n",
        "with tf.device('/gpu:0'):\n",
        "    model_name = 'CNN'\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=100,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "#model.add(Masking(mask_value=0.0))\n",
        "    model.add(Conv1D(128, 3))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbhcZUWdYDy",
        "outputId": "342f5478-7012-4267-adb5-b68baf403592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 23s 68ms/step - loss: 0.5369 - accuracy: 0.7159 - val_loss: 0.4810 - val_accuracy: 0.7571\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 19s 61ms/step - loss: 0.2505 - accuracy: 0.8990 - val_loss: 0.5483 - val_accuracy: 0.7451\n",
            "CPU times: user 13.6 s, sys: 5.36 s, total: 19 s\n",
            "Wall time: 42.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run training on GPU\n",
        "with tf.device('/gpu:0'):\n",
        "    early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='logs/'+ model_name, \n",
        "        write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYK0THNEdasw",
        "outputId": "5cde2016-a7c2-46f2-fc06-05a651d3cebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 9ms/step - loss: 0.5875 - accuracy: 0.7368\n",
            "\n",
            "\n",
            "Test score: 0.58748859167099\n",
            "Test accuracy: 0.7367632389068604\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfLpVUccddBm"
      },
      "source": [
        "# CNN -> LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1KIsl0dgEm",
        "outputId": "193807c1-dca0-409b-f157-6b1a02fc4f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/10\n",
            "319/319 [==============================] - 33s 101ms/step - loss: 0.5504 - accuracy: 0.7096 - val_loss: 0.4883 - val_accuracy: 0.7545\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 34s 107ms/step - loss: 0.2989 - accuracy: 0.8762 - val_loss: 0.5355 - val_accuracy: 0.7426\n",
            "CPU times: user 2min 21s, sys: 1min 15s, total: 3min 37s\n",
            "Wall time: 1min 7s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run inference on CPU\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model_name = 'CNN'\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "    model.add(Masking(mask_value=0.0))\n",
        "    model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='logs/'+ model_name, \n",
        "        write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1cly0CPdizk",
        "outputId": "e729ae05-8fcb-4a48-b442-5934717fb137",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 5s 96ms/step - loss: 0.5637 - accuracy: 0.7397\n",
            "\n",
            "\n",
            "Test score: 0.563737690448761\n",
            "Test accuracy: 0.7396728992462158\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Vbxz1QdmGl"
      },
      "source": [
        "# LSTM -> CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbYV4991dqG2",
        "outputId": "617fddc5-103f-49e5-8fc8-d22141a66b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 24s 73ms/step - loss: 0.5565 - accuracy: 0.7029 - val_loss: 0.4951 - val_accuracy: 0.7506\n",
            "Epoch 2/10\n",
            "319/319 [==============================] - 26s 80ms/step - loss: 0.3177 - accuracy: 0.8700 - val_loss: 0.5326 - val_accuracy: 0.7451\n",
            "CPU times: user 1min 43s, sys: 1min 1s, total: 2min 44s\n",
            "Wall time: 50.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Run inference on CPU\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    \n",
        "    model_name = 'LSTM -> CNN'\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "    model.add(Masking(mask_value=0.0))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(Conv1D(64, 3, activation='relu', padding=\"same\"))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='logs/'+ model_name, \n",
        "        write_graph=False, update_freq=100, profile_batch=0)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biA22UYDdtWQ",
        "outputId": "c52a580a-4234-4786-e73e-7f93cea9d0d4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 2s 25ms/step - loss: 0.5641 - accuracy: 0.7379\n",
            "\n",
            "\n",
            "Test score: 0.5641102194786072\n",
            "Test accuracy: 0.7379094362258911\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5uJznLqdwfi"
      },
      "source": [
        "Similar results on each model. Just RNN is slighrly better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}