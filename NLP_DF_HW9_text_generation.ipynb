{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfridland/NLP/blob/HW9/NLP_DF_HW9_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8e334e",
      "metadata": {
        "id": "3c8e334e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cfd749",
      "metadata": {
        "id": "56cfd749",
        "outputId": "ce65fd4c-640b-446e-dc51-b82a524cc9fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
        "is_cuda_gpu_available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97bc9d4",
      "metadata": {
        "id": "d97bc9d4",
        "outputId": "a41116d7-c954-4657-bc16-68de0002d4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cb52665",
      "metadata": {
        "id": "7cb52665",
        "outputId": "759d6de5-d509-48ff-f867-a8a29c11f05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Idiot\r\n",
            "\r\n",
            "by Fyodor Dostoyevsky\r\n",
            "\r\n",
            "\n",
            "PART I\r\n",
            "\r\n",
            "I.\r\n",
            "\r\n",
            "Towards the end of November, during a thaw, at nine o’clock one\r\n",
            "morning, a train on the Warsaw and Petersburg railway was approaching\r\n",
            "the latter city at full speed. The morning was so damp and misty that\r\n",
            "it was only with great difficulty that the day succeeded in breaking;\r\n",
            "and it was impossible to distinguish anything more than a few yards\n"
          ]
        }
      ],
      "source": [
        "text = open('idiot.txt', 'rb').read().decode(encoding='utf-8')\n",
        "print(text[:400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e6fa2b",
      "metadata": {
        "id": "d6e6fa2b",
        "outputId": "c652b968-6d55-44a4-ffcc-c3abead96644"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create vocab in chars of text\n",
        "vocab = sorted(set(text))\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946d451a",
      "metadata": {
        "id": "946d451a",
        "outputId": "48a247bc-f453-472c-a881-ff9b8aa14892"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1393505"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create mapping a chars\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "len(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2f3e0c",
      "metadata": {
        "id": "bd2f3e0c",
        "outputId": "8f902bcd-24d3-43a8-bd70-3457cd0828c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "I\n"
          ]
        }
      ],
      "source": [
        "len_seq = 150\n",
        "examples_per_epoch = len(text)//(len_seq + 1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48198cc6",
      "metadata": {
        "id": "48198cc6",
        "outputId": "6ef72c15-00e5-414a-b785-c50eb26813ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'The Idiot\\r\\n\\r\\nby Fyodor Dostoyevsky\\r\\n\\r\\n\\nPART I\\r\\n\\r\\nI.\\r\\n\\r\\nTowards the end of November, during a thaw, at nine o’clock one\\r\\nmorning, a train on the Warsaw '\n",
            "'and Petersburg railway was approaching\\r\\nthe latter city at full speed. The morning was so damp and misty that\\r\\nit was only with great difficulty that t'\n",
            "'he day succeeded in breaking;\\r\\nand it was impossible to distinguish anything more than a few yards\\r\\naway from the carriage windows.\\r\\n\\r\\nSome of the pass'\n",
            "'engers by this particular train were returning from\\r\\nabroad; but the third-class carriages were the best filled, chiefly\\r\\nwith insignificant persons of'\n",
            "' various occupations and degrees, picked\\r\\nup at the different stations nearer town. All of them seemed weary, and\\r\\nmost of them had sleepy eyes and a s'\n"
          ]
        }
      ],
      "source": [
        "sequences = char_dataset.batch(len_seq + 1, drop_remainder = True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f989bd1",
      "metadata": {
        "id": "1f989bd1"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7a992d",
      "metadata": {
        "id": "aa7a992d",
        "outputId": "58a3def0-b426-4545-b671-c815aeca2089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input data:  'The Idiot\\r\\n\\r\\nby Fyodor Dostoyevsky\\r\\n\\r\\n\\nPART I\\r\\n\\r\\nI.\\r\\n\\r\\nTowards the end of November, during a thaw, at nine o’clock one\\r\\nmorning, a train on the Warsaw'\n",
            "Target data: 'he Idiot\\r\\n\\r\\nby Fyodor Dostoyevsky\\r\\n\\r\\n\\nPART I\\r\\n\\r\\nI.\\r\\n\\r\\nTowards the end of November, during a thaw, at nine o’clock one\\r\\nmorning, a train on the Warsaw '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27b7d02d",
      "metadata": {
        "id": "27b7d02d",
        "outputId": "b8fd0d84-16ca-4374-e24e-edb6aaa3d3ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(64, 150), dtype=tf.int64, name=None), TensorSpec(shape=(64, 150), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e409ac1",
      "metadata": {
        "id": "7e409ac1"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128\n",
        "rnn_units = 1024\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "         [\n",
        "           tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "           tf.keras.layers.LSTM(rnn_units, return_sequences = True),\n",
        "           tf.keras.layers.Dense(vocab_size)\n",
        "         ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eac02d6b",
      "metadata": {
        "id": "eac02d6b"
      },
      "outputs": [],
      "source": [
        "class RNNgenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, batch_size):\n",
        "        super(RNNgenerator, self).__init__()\n",
        "        \n",
        "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru1 = tf.keras.layers.GRU(rnn_units, return_sequences = True, recurrent_initializer = 'glorot_uniform')\n",
        "        self.gru2 = tf.keras.layers.GRU(rnn_units, return_sequences = True, recurrent_initializer = 'glorot_uniform')\n",
        "        self.gru3 = tf.keras.layers.GRU(rnn_units, return_sequences = True, recurrent_initializer = 'glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    def call(self, x):\n",
        "        emb_x = self.emb(x)\n",
        "        x1 = self.gru1(emb_x)\n",
        "        x = x1\n",
        "        for _ in range(3):\n",
        "            x = self.gru2(x)\n",
        "        x = (x + x1) / 2\n",
        "        return self.fc(x)\n",
        "    \n",
        "model = RNNgenerator(vocab_size, embedding_dim, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ecb729",
      "metadata": {
        "id": "76ecb729"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        \n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        \n",
        "            tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "            tf.keras.layers.LSTM(rnn_units,\n",
        "                                return_sequences=True,\n",
        "                                stateful=True,\n",
        "                                recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "             tf.keras.layers.LSTM(rnn_units,\n",
        "                                return_sequences=True,\n",
        "                                stateful=True,\n",
        "                                recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "            tf.keras.layers.LSTM(rnn_units,\n",
        "                                return_sequences=True,\n",
        "                                stateful=True,\n",
        "                                recurrent_initializer='glorot_uniform'),\n",
        "            tf.keras.layers.LSTM(rnn_units,\n",
        "                                return_sequences=True,\n",
        "                                stateful=True,\n",
        "                                recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "            tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e10c3b1",
      "metadata": {
        "id": "3e10c3b1"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794f69db",
      "metadata": {
        "id": "794f69db",
        "outputId": "85ba8be7-3f16-4d5e-e2ba-d08f8d6da9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 150, 94) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d822cb",
      "metadata": {
        "id": "d1d822cb",
        "outputId": "bb368f50-1854-4281-ee3b-1d86c798e658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (64, None, 128)           12032     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (64, None, 1024)          4722688   \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (64, None, 94)            96350     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,401,886\n",
            "Trainable params: 38,401,886\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7d48ec",
      "metadata": {
        "id": "bc7d48ec",
        "outputId": "dc906a60-e177-42ff-d2d7-5beee3e30911"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(150, 94), dtype=float32, numpy=\n",
              "array([[-5.2970708e-09, -2.3660582e-06, -3.7212228e-06, ...,\n",
              "        -8.8760299e-07,  4.0124456e-07, -1.4392950e-06],\n",
              "       [ 8.8843086e-07, -8.4582762e-06, -1.0565443e-05, ...,\n",
              "        -4.0042592e-06,  2.4585047e-06, -5.9430004e-06],\n",
              "       [ 2.4757992e-06, -2.0555362e-05, -1.7189132e-05, ...,\n",
              "        -1.1777334e-05,  6.6926914e-06, -1.2729175e-05],\n",
              "       ...,\n",
              "       [ 5.7078735e-04,  1.0774263e-04,  7.2236895e-04, ...,\n",
              "        -1.4427755e-03, -1.0840442e-03,  1.0496326e-03],\n",
              "       [ 6.4854865e-04,  1.4464912e-04,  7.7500474e-04, ...,\n",
              "        -1.4363336e-03, -1.0501007e-03,  1.0179465e-03],\n",
              "       [ 7.2517141e-04,  1.8528110e-04,  8.3676202e-04, ...,\n",
              "        -1.4271148e-03, -1.0120168e-03,  9.7194582e-04]], dtype=float32)>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_batch_predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def01211",
      "metadata": {
        "id": "def01211"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[3], num_samples = 1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis = -1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4702f5",
      "metadata": {
        "id": "0c4702f5",
        "outputId": "606a3795-2f0f-4854-9147-fb3059e79dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: \n",
            " ' of life, but as a whole they are accursed.\\r\\nThe whole tendency of our latest centuries, in its scientific and\\r\\nmaterialistic aspect, is most probably'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'ULêçVr[dèvppAPY2RZ\\n7‘2Hv$r\\'Kn\\'MIf‘èvàP3gMMvrD9W*Xg\\'7o*CT9ênKa\"fo[7 ]3é-TD8ca)!J‘)\\n6\"w,L_9;k\\ns]?on’7T“F’àUkd%’8e?\\'z\"5D“è/X2‘—s\\'éà8NéW)’-n]]c_T/7wbzBzER'\n"
          ]
        }
      ],
      "source": [
        "#  what we are giving to a non-trained model\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[3]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15c659f",
      "metadata": {
        "id": "f15c659f"
      },
      "outputs": [],
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc86d0e",
      "metadata": {
        "id": "1dc86d0e",
        "outputId": "078ac4ed-7f7a-467e-a7c3-feb0f569e220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 150, 94)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.5431714\n"
          ]
        }
      ],
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f050fb",
      "metadata": {
        "id": "30f050fb"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2974fa65",
      "metadata": {
        "id": "2974fa65"
      },
      "outputs": [],
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc4757d",
      "metadata": {
        "id": "7dc4757d"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./training_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4ec6c4",
      "metadata": {
        "id": "7f4ec6c4",
        "outputId": "f4d637ba-1c16-4c7e-a4d1-20f7594be3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: ./training_checkpoints: No such file or directory\r\n"
          ]
        }
      ],
      "source": [
        "!ls ./training_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e9fc32",
      "metadata": {
        "id": "a1e9fc32"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=88*3,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b1dd6dc",
      "metadata": {
        "id": "5b1dd6dc"
      },
      "outputs": [],
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67b420f",
      "metadata": {
        "id": "e67b420f"
      },
      "outputs": [],
      "source": [
        "# tf.config.set_visible_devices([], 'GPU')\n",
        "# with tf.device('/cpu:0'):\n",
        "physical_devices = tf.config.list_physical_devices('GPU'); \n",
        "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13fc857",
      "metadata": {
        "id": "a13fc857",
        "outputId": "27a4b47b-331d-4b69-c2e2-2c17e511d222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "144/144 [==============================] - 88s 604ms/step - loss: 1.3644\n",
            "Epoch 2/50\n",
            "144/144 [==============================] - 86s 595ms/step - loss: 1.2999\n",
            "Epoch 3/50\n",
            "144/144 [==============================] - 87s 598ms/step - loss: 1.2508\n",
            "Epoch 4/50\n",
            "144/144 [==============================] - 87s 597ms/step - loss: 1.2128\n",
            "Epoch 5/50\n",
            "144/144 [==============================] - 86s 594ms/step - loss: 1.1828\n",
            "Epoch 6/50\n",
            "144/144 [==============================] - 87s 599ms/step - loss: 1.1550\n",
            "Epoch 7/50\n",
            "144/144 [==============================] - 86s 594ms/step - loss: 1.1297\n",
            "Epoch 8/50\n",
            "144/144 [==============================] - 87s 599ms/step - loss: 1.1065\n",
            "Epoch 9/50\n",
            "144/144 [==============================] - 651s 5s/step - loss: 1.0849\n",
            "Epoch 10/50\n",
            "144/144 [==============================] - 87s 601ms/step - loss: 1.0657\n",
            "Epoch 11/50\n",
            "144/144 [==============================] - 86s 595ms/step - loss: 1.0419\n",
            "Epoch 12/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 1.0201\n",
            "Epoch 13/50\n",
            "144/144 [==============================] - 86s 594ms/step - loss: 0.9989\n",
            "Epoch 14/50\n",
            "144/144 [==============================] - 87s 602ms/step - loss: 0.9760\n",
            "Epoch 15/50\n",
            "144/144 [==============================] - 87s 602ms/step - loss: 0.9527\n",
            "Epoch 16/50\n",
            "144/144 [==============================] - 86s 596ms/step - loss: 0.9272\n",
            "Epoch 17/50\n",
            "144/144 [==============================] - 87s 603ms/step - loss: 0.9009\n",
            "Epoch 18/50\n",
            "144/144 [==============================] - 89s 614ms/step - loss: 0.8729\n",
            "Epoch 19/50\n",
            "144/144 [==============================] - 88s 605ms/step - loss: 0.8432\n",
            "Epoch 20/50\n",
            "144/144 [==============================] - 87s 599ms/step - loss: 0.8130\n",
            "Epoch 21/50\n",
            "144/144 [==============================] - 87s 599ms/step - loss: 0.7800\n",
            "Epoch 22/50\n",
            "144/144 [==============================] - 86s 596ms/step - loss: 0.7451\n",
            "Epoch 23/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.7119\n",
            "Epoch 24/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.6757\n",
            "Epoch 25/50\n",
            "144/144 [==============================] - 87s 602ms/step - loss: 0.6389\n",
            "Epoch 26/50\n",
            "144/144 [==============================] - 88s 607ms/step - loss: 0.6020\n",
            "Epoch 27/50\n",
            "144/144 [==============================] - 88s 606ms/step - loss: 0.5670\n",
            "Epoch 28/50\n",
            "144/144 [==============================] - 88s 608ms/step - loss: 0.5295\n",
            "Epoch 29/50\n",
            "144/144 [==============================] - 86s 596ms/step - loss: 0.4948\n",
            "Epoch 30/50\n",
            "144/144 [==============================] - 87s 603ms/step - loss: 0.4629\n",
            "Epoch 31/50\n",
            "144/144 [==============================] - 86s 597ms/step - loss: 0.4305\n",
            "Epoch 32/50\n",
            "144/144 [==============================] - 89s 612ms/step - loss: 0.4034\n",
            "Epoch 33/50\n",
            "144/144 [==============================] - 87s 598ms/step - loss: 0.3760\n",
            "Epoch 34/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.3523\n",
            "Epoch 35/50\n",
            "144/144 [==============================] - 88s 605ms/step - loss: 0.3320\n",
            "Epoch 36/50\n",
            "144/144 [==============================] - 88s 609ms/step - loss: 0.3124\n",
            "Epoch 37/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.2971\n",
            "Epoch 38/50\n",
            "144/144 [==============================] - 87s 598ms/step - loss: 0.2826\n",
            "Epoch 39/50\n",
            "144/144 [==============================] - 89s 611ms/step - loss: 0.2722\n",
            "Epoch 40/50\n",
            "144/144 [==============================] - 86s 596ms/step - loss: 0.2615\n",
            "Epoch 41/50\n",
            "144/144 [==============================] - 87s 603ms/step - loss: 0.2500\n",
            "Epoch 42/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.2433\n",
            "Epoch 43/50\n",
            "144/144 [==============================] - 88s 606ms/step - loss: 0.2364\n",
            "Epoch 44/50\n",
            "144/144 [==============================] - 87s 603ms/step - loss: 0.2290\n",
            "Epoch 45/50\n",
            "144/144 [==============================] - 89s 615ms/step - loss: 0.2245\n",
            "Epoch 46/50\n",
            "144/144 [==============================] - 87s 603ms/step - loss: 0.2219\n",
            "Epoch 47/50\n",
            "144/144 [==============================] - 88s 608ms/step - loss: 0.2195\n",
            "Epoch 48/50\n",
            "144/144 [==============================] - 88s 604ms/step - loss: 0.2149\n",
            "Epoch 49/50\n",
            "144/144 [==============================] - 87s 600ms/step - loss: 0.2151\n",
            "Epoch 50/50\n",
            "144/144 [==============================] - 88s 607ms/step - loss: 0.2119\n",
            "CPU times: user 5min 48s, sys: 1min 34s, total: 7min 23s\n",
            "Wall time: 1h 22min 4s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "EPOCHS = 50\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05050440",
      "metadata": {
        "id": "05050440"
      },
      "outputs": [],
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5cf5e4",
      "metadata": {
        "id": "3f5cf5e4",
        "outputId": "2ef21015-a310-4034-f490-f4c6c0240ff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_50'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a178ea",
      "metadata": {
        "id": "a2a178ea"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23ceb0e",
      "metadata": {
        "id": "c23ceb0e",
        "outputId": "61027d11-1d22-44ab-e905-6117ec59d22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (1, None, 128)            12032     \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (1, None, 1024)           4722688   \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, None, 94)             96350     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,401,886\n",
            "Trainable params: 38,401,886\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb96bb12",
      "metadata": {
        "id": "bb96bb12"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 500\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e964e618",
      "metadata": {
        "id": "e964e618",
        "outputId": "105d9d63-e46b-4a3c-9928-d3e679773427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The morning was so damp and misty that the worst of it\r\n",
            "all, to the presence of your friends, I think I ought to explain,\r\n",
            "gentlemen, that I only did so to assert our rights, though she trembled in\r\n",
            "all her limbs. And when the subject of this murder of the Pope of Rome is,\r\n",
            "he will never speak to you again. She did not come here to marry Rogojin. I\r\n",
            "dreamt of the story.\r\n",
            "\r\n",
            "“As to the rest for an instant and then paid a very difficult and malice.\r\n",
            "\r\n",
            "“That is proved by my peeper” my thought, enough!” he cried, suddenly. “I see I have b\n"
          ]
        }
      ],
      "source": [
        "text_ = generate_text(model, start_string=u\"The morning was so damp and misty that \")\n",
        "print(text_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac3c746",
      "metadata": {
        "id": "9ac3c746"
      },
      "outputs": [],
      "source": [
        "len(text_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74f2e45",
      "metadata": {
        "id": "e74f2e45"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}