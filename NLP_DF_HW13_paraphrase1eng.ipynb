{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfridland/NLP/blob/HW13/NLP_DF_HW13_paraphrase1eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1074b225",
      "metadata": {
        "id": "1074b225",
        "outputId": "6e74eadd-9fed-4170-bffd-4c82156412e7",
        "colab": {
          "referenced_widgets": [
            "6c463a82078b4f3592aefc2eff269057"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset csv (/Users/evamelissatasdemir/.cache/huggingface/datasets/humarin___csv/humarin--chatgpt-paraphrases-56e87c47b965542a/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c463a82078b4f3592aefc2eff269057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'text': 'What is the step by step guide to invest in share market in india?',\n",
              " 'paraphrases': \"['Can you provide a detailed procedure for investing in the Indian stock market?', 'What are the sequential instructions for investing in shares in India?', 'Could you outline the step-by-step process for investing in the Indian share market?', 'What is the systematic guide to investing in the Indian stock exchange?', 'Can you provide a comprehensive guide on how to invest in the Indian share market?']\",\n",
              " 'category': 'question',\n",
              " 'source': 'quora'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "my_dataset_dictionary = load_dataset(\"humarin/chatgpt-paraphrases\")\n",
        "my_dataset_dictionary['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d214da2",
      "metadata": {
        "id": "2d214da2",
        "outputId": "6c10c428-9ad7-42b4-df93-1638ee61a190"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'paraphrases', 'category', 'source'],\n",
              "        num_rows: 419197\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_dataset_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4221d6a",
      "metadata": {
        "id": "e4221d6a",
        "outputId": "6128ff30-9511-4c85-b6f4-1d4d8c359e61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'paraphrases', 'category', 'source'],\n",
              "    num_rows: 419197\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_dataset_dictionary['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2817ba",
      "metadata": {
        "id": "6c2817ba",
        "outputId": "6d80e3f6-4ead-4444-8008-29192f622fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['Can you tell me about the history of the Kohinoor (Koh-i-Noor) Diamond?', 'What is the tale behind the Kohinoor (Koh-i-Noor) Diamond?', 'Could you narrate the story of the Kohinoor (Koh-i-Noor) Diamond?', 'What is the account of the Kohinoor (Koh-i-Noor) Diamond?', 'Can you describe the legend of the Kohinoor (Koh-i-Noor) Diamond?']\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_dataset_dictionary['train']['paraphrases'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c675da9",
      "metadata": {
        "id": "1c675da9",
        "outputId": "35b079ef-8075-40da-8d66-ce55c4062245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What is the story of Kohinoor (Koh-i-Noor) Diamond?'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_dataset_dictionary['train']['text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c258dcf3",
      "metadata": {
        "id": "c258dcf3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "@property\n",
        "def device(self) -> torch.device:\n",
        "        if torch.cuda.is_available():\n",
        "            return torch.device(\"cuda\")\n",
        "        elif torch.backends.mps.is_available():\n",
        "            return torch.device(\"mps\")\n",
        "        else:\n",
        "\n",
        "            return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52adcfb",
      "metadata": {
        "id": "b52adcfb",
        "outputId": "767d0a38-8e5a-4d01-b56e-f276afbc40f2",
        "colab": {
          "referenced_widgets": [
            "8aeb40644e9e4a4eb81fdad30e5b83a6",
            "89ec3f89134744a39e32dc6aaad7ca38",
            "8121987014544000b9bc971b63cb5280",
            "63e95539fc314aefb491f5ae5d87e584",
            "4cbd41675e634354a0b1fb7256f31e7f",
            "cdc0c1d05f9f485891a9c71e0acc2bee"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aeb40644e9e4a4eb81fdad30e5b83a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89ec3f89134744a39e32dc6aaad7ca38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8121987014544000b9bc971b63cb5280",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e95539fc314aefb491f5ae5d87e584",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cbd41675e634354a0b1fb7256f31e7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdc0c1d05f9f485891a9c71e0acc2bee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Germany will provide more than $1.4 billion in financial support to Holocaust survivors in the next year, as the country prepares to pay more than\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "MODEL_NAME = 'humarin/chatgpt_paraphraser_on_T5_base'\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model.to('mps');\n",
        "model.eval();\n",
        "\n",
        "\n",
        "def paraphrase(text, beams=5, grams=4, do_sample=False):\n",
        "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
        "    max_size = int(x.input_ids.shape[1] * 1.5 + 10)\n",
        "    out = model.generate(**x, encoder_no_repeat_ngram_size=grams, num_beams=beams, max_length=max_size, do_sample=do_sample)\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(paraphrase('Germany will pay Holocaust survivors over $1.4 billion next year.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e49538",
      "metadata": {
        "id": "67e49538"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "device='mps'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
        "# batch = tokenizer(text1, text2, return_tensors='pt').to(model.device)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to('mps')\n",
        "\n",
        "def paraphrase(\n",
        "\n",
        "    question,\n",
        "    num_beams=5,\n",
        "    num_beam_groups=5,\n",
        "    num_return_sequences=5,\n",
        "    repetition_penalty=10.0,\n",
        "    diversity_penalty=3.0,\n",
        "    no_repeat_ngram_size=2,\n",
        "    temperature=0.7,\n",
        "    max_length=128\n",
        "\n",
        "):\n",
        "    input_ids = tokenizer(\n",
        "        f'paraphrase: {question}',\n",
        "        return_tensors=\"pt\", padding=\"longest\",\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "    ).input_ids.to('mps')\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
        "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
        "        max_length=max_length, diversity_penalty=diversity_penalty,\n",
        "    )\n",
        "\n",
        "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea49c6b",
      "metadata": {
        "id": "cea49c6b",
        "outputId": "94af26b5-113a-4abf-f411-ed93152a0c94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What are some must-see places in New York?',\n",
              " 'Can you suggest some must-see spots in New York?',\n",
              " 'Where should one go to experience the best NYC has to offer?',\n",
              " 'Which places should I visit in New York?',\n",
              " 'What are the top destinations to explore in New York?']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'What are the best places to see in New York?'\n",
        "paraphrase(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f8d92b",
      "metadata": {
        "id": "38f8d92b",
        "outputId": "df7f7b3f-f414-4926-9449-9eba1856736a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['In May and June 2000, Rammstein travelled to the south of France to record his album Mutter, which was mixed in Stockholm in October of that year.',\n",
              " 'The album Mutter by Rammstein was recorded in the south of France during May and June 2000, with mixing taking place in Stockholm in October of that year.',\n",
              " 'The album Mutter by Rammstein was recorded in the south of France during May and June 2000, with mixing taking place in Stockholm in October of that year. It',\n",
              " 'Mutter, the album released by Rammstein, was recorded in southern France during May and June 2000, with mixing taking place between October and September.',\n",
              " 'In May and June 2000, Rammstein recorded his album Mutter in the south of France, with the mix being made at Stockholm during October.']"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Rammstein's album Mutter was recorded in the south of France in May and June 2000, and mixed in Stockholm in October of that year.\"\n",
        "paraphrase(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ceda63f",
      "metadata": {
        "id": "5ceda63f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}